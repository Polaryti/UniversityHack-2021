{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eda.input import input_parser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## for statistical tests\n",
    "# import scipy\n",
    "# import statsmodels.formula.api as smf\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
    "## for explainer\n",
    "# from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataframe files\n",
    "input_parser(r'data/Modelar_UH2021.txt', 'base')\n",
    "input_parser(r'data/Estimar_UH2021.txt', 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data base\n",
    "df = pd.read_csv(filepath_or_buffer=r'data/Modelar_UH2021_base.csv', sep='|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data type base\n",
    "def recognize_type(dtf, col, max_cat=20):\n",
    "    if (dtf[col].dtype == \"O\") | (dtf[col].nunique() < max_cat):\n",
    "        return \"cat\"\n",
    "    else:\n",
    "        return \"num\"\n",
    "\n",
    "\n",
    "dic_cols = {col: recognize_type(\n",
    "    df, col, max_cat=20) for col in df.columns}\n",
    "heatmap = df.isnull()\n",
    "for k, v in dic_cols.items():\n",
    "    if v == \"num\":\n",
    "        heatmap[k] = heatmap[k].apply(lambda x: 0.5 if x is False else 1)\n",
    "    else:\n",
    "        heatmap[k] = heatmap[k].apply(lambda x: 0 if x is False else 1)\n",
    "sns.heatmap(heatmap, cbar=False).set_title('Dataset Overview')\n",
    "plt.show()\n",
    "print(\"\\033[1;37;40m Categerocial \", \"\\033[1;30;41m Numeric \", \"\\033[1;30;47m NaN \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the correlation\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, vmin=-1., vmax=1., annot=True, fmt='.2f', cmap=\"YlGnBu\", cbar=True, linewidths=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Definition of auxiliar methods and variables\n",
    "actual_price = {}\n",
    "first_price = {}\n",
    "# Complete the prices with the sample with the same \"id\"\n",
    "def __price_completer(row):\n",
    "    precio = float(row['precio'].replace(',', '.')) if isinstance(row['precio'], str) else row['precio']\n",
    "    identificador = str(row['id'])\n",
    "    if math.isnan(precio):\n",
    "        precio = actual_price.get(identificador, -1.0)\n",
    "    else:\n",
    "        actual_price[identificador] = precio\n",
    "        if first_price.get(identificador) == None:\n",
    "            first_price[identificador] = precio\n",
    "    return precio\n",
    "\n",
    "# Complete the price by proximity\n",
    "def __price_completer_proximity(row):\n",
    "    precio = row['precio']\n",
    "    if precio == -1.0:\n",
    "        identificador = str(row['id'])\n",
    "        precio = first_price.get(identificador)\n",
    "    return precio\n",
    "\n",
    "# Method to preprocesing the input files\n",
    "def input_parser(path, option):\n",
    "    df = pd.read_csv(filepath_or_buffer=path, sep='|')\n",
    "    # There are duplicated samples\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    if option != 'base':\n",
    "        # Drop the useless hour of 'fecha' column\n",
    "        df['fecha'] = df['fecha'].apply(lambda x: x.replace(' 0:00:00', ''))\n",
    "        # Completation of 'precio' column\n",
    "        df['precio'] = df.apply(__price_completer, axis=1)\n",
    "        df['precio'] = df.apply(__price_completer_proximity, axis=1)\n",
    "        # Split of 'fecha' column\n",
    "        df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "        df['dia'] = pd.DatetimeIndex(df['fecha']).day\n",
    "        df['mes'] = pd.DatetimeIndex(df['fecha']).month\n",
    "        df['anyo'] = pd.DatetimeIndex(df['fecha']).year\n",
    "        df.drop('fecha', axis=1, inplace=True)\n",
    "\n",
    "        # One-hot encoding of 'estado'\n",
    "        df = pd.concat([df, pd.get_dummies(pd.get_dummies(\n",
    "            df['estado'], prefix='estado'))], axis=1).drop(['estado'], axis=1)\n",
    "\n",
    "        # One-hot encoding of 'categoria_uno'\n",
    "        df = pd.concat([df, pd.get_dummies(pd.get_dummies(\n",
    "            df['categoria_uno'], prefix='categoria_uno'))], axis=1).drop(['categoria_uno'], axis=1)\n",
    "\n",
    "        # One-hot encoding of 'dia_atipico'\n",
    "        df = pd.concat([df, pd.get_dummies(pd.get_dummies(\n",
    "            df['dia_atipico'], prefix='dia_atipico'))], axis=1).drop(['dia_atipico'], axis=1)\n",
    "\n",
    "        df['antiguedad'].fillna(0, inplace=True)\n",
    "\n",
    "        if option == 'drop':\n",
    "            # 'categoria_dos' drop\n",
    "            df.drop('categoria_dos', axis=1, inplace=True)\n",
    "        else:\n",
    "            # 'categoria_dos' corrupted samples correction\n",
    "            df['categoria_dos'] = df['categoria_dos'].apply(\n",
    "                lambda x: 0 if math.isnan(x) else x)\n",
    "\n",
    "    df.to_csv(index=False, path_or_buf=path.replace(\n",
    "        '.txt', '') + \"_\" + option + \".csv\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Modelar\" and \"Estimar\" dataframes processed\n",
    "input_parser(r\"data/Modelar_UH2021.txt\", 'drop')\n",
    "modelar = pd.read_csv(r'data/Modelar_UH2021_drop.csv', sep='|', low_memory=False)\n",
    "# \"Estimar\" dataframe has not samples with \"estado\" = \"Rotura\" and that column is\n",
    "# converted to one-hot vector so it must be dropped\n",
    "modelar = modelar.drop('estado_Rotura', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data processed\n",
    "modelar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data type base\n",
    "dic_cols = {col: recognize_type(\n",
    "    modelar, col, max_cat=20) for col in modelar.columns}\n",
    "heatmap = modelar.isnull()\n",
    "for k, v in dic_cols.items():\n",
    "    if v == \"num\":\n",
    "        heatmap[k] = heatmap[k].apply(lambda x: 0.5 if x is False else 1)\n",
    "    else:\n",
    "        heatmap[k] = heatmap[k].apply(lambda x: 0 if x is False else 1)\n",
    "sns.heatmap(heatmap, cbar=False).set_title('Dataset Overview')\n",
    "plt.show()\n",
    "print(\"\\033[1;37;40m Categerocial \", \"\\033[1;30;47m Numeric \", \"\\033[1;30;41m NaN \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the correlation\n",
    "corr_matrix = modelar.corr()\n",
    "sns.heatmap(corr_matrix, vmin=-1., vmax=1., fmt='.2f', cmap=\"YlGnBu\", cbar=True, linewidths=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other analysis\n",
    "from src.eda.pcr import pcr\n",
    "from src.eda.permutation import permutation\n",
    "from src.eda.importance_corr import importance_corr\n",
    "from src.eda.hiperparameter import hiperparameter_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Regression and PLS\n",
    "pcr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation analysis importance\n",
    "permutation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation importance analysis\n",
    "importance_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train.trainIsotonic import isotonic\n",
    "from src.train.trainLogistic import logistic\n",
    "from src.train.trainMLP import mlp\n",
    "from src.train.trainRidge import kernel_ridge\n",
    "from src.train.trainXGB import xgb_reg\n",
    "from src.train.trainTF import tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isotronic regressor\n",
    "isotonic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regressor\n",
    "logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP regressor\n",
    "mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel ridge regressor\n",
    "kernel_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost regressor\n",
    "xgb_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow neural network\n",
    "tf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}