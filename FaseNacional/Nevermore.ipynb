{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports and libraries\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of auxiliar methods and variables\n",
    "actual_price = {}\n",
    "first_price = {}\n",
    "# Complete the prices with the sample with the same \"id\"\n",
    "def __price_completer(row):\n",
    "    precio = float(row['precio'].replace(',', '.')) if isinstance(row['precio'], str) else row['precio']\n",
    "    identificador = str(row['id'])\n",
    "    if math.isnan(precio):\n",
    "        precio = actual_price.get(identificador, -1.0)\n",
    "    else:\n",
    "        actual_price[identificador] = precio\n",
    "        if first_price.get(identificador) == None:\n",
    "            first_price[identificador] = precio\n",
    "    return precio\n",
    "\n",
    "# Complete the price by proximity\n",
    "def __price_completer_proximity(row):\n",
    "    precio = row['precio']\n",
    "    if precio == -1.0:\n",
    "        identificador = str(row['id'])\n",
    "        precio = first_price.get(identificador)\n",
    "    return precio\n",
    "\n",
    "# Calculate favorable cases\n",
    "def __favorable_cases(test, pred):\n",
    "    rotura = 0\n",
    "    total = len(test)\n",
    "    for i in range(total):\n",
    "        if pred[i] < test[i]:\n",
    "            rotura += 1\n",
    "\n",
    "    return (total - rotura) / total\n",
    "\n",
    "# Calculate datathon metric\n",
    "def __datathon_metric(y_test, y_train, pred):\n",
    "    rrmse = math.sqrt(mean_squared_error(\n",
    "        y_test.values, pred)) / y_train.mean()\n",
    "    cf = __favorable_cases(y_test.values, pred)\n",
    "    return (0.7 * rrmse) + (0.3 * (1 - cf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to preprocesing the input files\n",
    "def input_parser(path, option):\n",
    "    df = pd.read_csv(filepath_or_buffer=path, sep='|')\n",
    "    # There are duplicated samples\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    if option != 'base':\n",
    "        # Drop the useless hour of 'fecha' column\n",
    "        df['fecha'] = df['fecha'].apply(lambda x: x.replace(' 0:00:00', ''))\n",
    "        # Completation of 'precio' column\n",
    "        df['precio'] = df.apply(__price_completer, axis=1)\n",
    "        df['precio'] = df.apply(__price_completer_proximity, axis=1)\n",
    "        # Split of 'fecha' column\n",
    "        df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "        df['dia'] = pd.DatetimeIndex(df['fecha']).day\n",
    "        df['mes'] = pd.DatetimeIndex(df['fecha']).month\n",
    "        df['anyo'] = pd.DatetimeIndex(df['fecha']).year\n",
    "        df.drop('fecha', axis=1, inplace=True)\n",
    "\n",
    "        # One-hot encoding of 'estado'\n",
    "        df = pd.concat([df, pd.get_dummies(pd.get_dummies(\n",
    "            df['estado'], prefix='estado'))], axis=1).drop(['estado'], axis=1)\n",
    "\n",
    "        # One-hot encoding of 'categoria_uno'\n",
    "        df = pd.concat([df, pd.get_dummies(pd.get_dummies(\n",
    "            df['categoria_uno'], prefix='categoria_uno'))], axis=1).drop(['categoria_uno'], axis=1)\n",
    "\n",
    "        # One-hot encoding of 'dia_atipico'\n",
    "        df = pd.concat([df, pd.get_dummies(pd.get_dummies(\n",
    "            df['dia_atipico'], prefix='dia_atipico'))], axis=1).drop(['dia_atipico'], axis=1)\n",
    "\n",
    "        df['antiguedad'].fillna(0, inplace=True)\n",
    "\n",
    "        if option == 'drop':\n",
    "            # 'categoria_dos' drop\n",
    "            df.drop('categoria_dos', axis=1, inplace=True)\n",
    "        else:\n",
    "            # 'categoria_dos' corrupted samples correction\n",
    "            df['categoria_dos'] = df['categoria_dos'].apply(\n",
    "                lambda x: 0 if math.isnan(x) else x)\n",
    "\n",
    "    df.to_csv(index=False, path_or_buf=path.replace(\n",
    "        '.txt', '') + \"_\" + option + \".csv\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Modelar\" and \"Estimar\" dataframes\n",
    "input_parser(r\"data/Modelar_UH2021.txt\", 'drop')\n",
    "modelar = pd.read_csv(r'data/Modelar_UH2021_drop.csv', sep='|', low_memory=False)\n",
    "# \"Estimar\" dataframe has not samples with \"estado\" = \"Rotura\" and that column is\n",
    "# converted to one-hot vector so it must be dropped\n",
    "modelar.drop('estado_Rotura', axis=1, inplace=True)\n",
    "input_parser(r\"data/Estimar_UH2021.txt\", 'drop')\n",
    "estimar = pd.read_csv(r\"data/Estimar_UH2021_drop.csv\", sep='|', low_memory=False)\n",
    "ids_estimar = set(estimar['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "total_mse = 0\n",
    "total_mae = 0\n",
    "total_cf = 0\n",
    "total_metrica = 0\n",
    "for index, row in modelar.iterrows():\n",
    "    if row['id'] in ids_estimar and row['id'] not in model_dict:\n",
    "        df_aux = modelar[modelar['id'] == row['id']]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_aux.loc[:, df_aux.columns != 'unidades_vendidas'], df_aux['unidades_vendidas'], test_size=0.25)\n",
    "\n",
    "        reg = RandomForestRegressor(\n",
    "            verbose=0, n_jobs=-1, n_estimators=150, min_samples_split=3, min_samples_leaf=2)\n",
    "        reg.fit(X_train, y_train)\n",
    "        pred = reg.predict(X_test)\n",
    "\n",
    "        rrmse = math.sqrt(mean_squared_error(y_test, pred)) / y_train.mean()\n",
    "        cf = __favorable_cases(y_test.values, pred)\n",
    "        metric = (0.7 * rrmse) + (0.3 * (1 - cf))\n",
    "\n",
    "        total_mse += mean_squared_error(y_test, pred)\n",
    "        total_mae += mean_absolute_error(y_test, pred)\n",
    "        total_cf += cf\n",
    "        total_metrica += metric\n",
    "\n",
    "        model_dict[row['id']] = reg\n",
    "\n",
    "print(f\"MSE: {total_mse / len(model_dict)}\")\n",
    "print(f\"MAE: {total_mae / len(model_dict)}\")\n",
    "print(f\"Favorable cases: {total_cf / len(model_dict)}\")\n",
    "print(f\"Datathon metric: {total_metrica / len(model_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the generation of response file\n",
    "with open(r'res/Nevermore.txt', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    csvwriter = csv.writer(csv_file, delimiter='|')\n",
    "    csvwriter.writerow(['FECHA', 'ID', 'UNIDADES'])\n",
    "\n",
    "    for index, row in estimar.iterrows():\n",
    "        aux = pd.DataFrame(columns=estimar.columns)\n",
    "        aux.loc[0] = row\n",
    "        est_pred = model_dict[row['id']].predict(aux)[0]\n",
    "        data_txt = f\"{int(estimar.iloc[index]['dia'])}/{int(estimar.iloc[index]['mes'])}/{int(estimar.iloc[index]['anyo'])}\"\n",
    "        csvwriter.writerow(\n",
    "            [data_txt, int(estimar.iloc[index]['id']), round(est_pred)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}