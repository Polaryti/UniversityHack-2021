{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('tfg': conda)",
   "metadata": {
    "interpreter": {
     "hash": "35e32d7887ee598a072419531948575ae93650ac835e4b71fee1695ca81c13d6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports and libraries\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of auxiliar methods and variables\n",
    "actual_price = {}\n",
    "first_price = {}\n",
    "# Complete the prices with the sample with the same \"id\"\n",
    "def __price_completer(row):\n",
    "    precio = float(row['precio'].replace(',', '.')) if isinstance(row['precio'], str) else row['precio']\n",
    "    identificador = str(row['id'])\n",
    "    if math.isnan(precio):\n",
    "        precio = actual_price.get(identificador, -1.0)\n",
    "    else:\n",
    "        actual_price[identificador] = precio\n",
    "        if first_price.get(identificador) == None:\n",
    "            first_price[identificador] = precio\n",
    "    return precio\n",
    "\n",
    "# Complete the price by proximity\n",
    "def __price_completer_proximity(row):\n",
    "    precio = row['precio']\n",
    "    if precio == -1.0:\n",
    "        identificador = str(row['id'])\n",
    "        precio = first_price.get(identificador)\n",
    "    return precio\n",
    "\n",
    "# Calculate favorable cases\n",
    "def __favorable_cases(test, pred):\n",
    "    rotura = 0\n",
    "    total = len(test)\n",
    "    for i in range(total):\n",
    "        if pred[i] < test[i]:\n",
    "            rotura += 1\n",
    "\n",
    "    return (total - rotura) / total\n",
    "\n",
    "# Calculate datathon metric\n",
    "def __datathon_metric(y_test, y_train, pred):\n",
    "    rrmse = math.sqrt(mean_squared_error(\n",
    "        y_test.values, pred)) / y_train.mean()\n",
    "    cf = __favorable_cases(y_test.values, pred)\n",
    "    return (0.7 * rrmse) + (0.3 * (1 - cf))\n",
    "\n",
    "# Convert YYYY-MM-DD to DD-MM-YYYY\n",
    "def __datetime_parser(datetime):\n",
    "    datetime = datetime.split('-')\n",
    "    return datetime[2] + '-' + datetime[1] + '-' + datetime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to preprocesing the input files\n",
    "def input_parser(path, option):\n",
    "    df = pd.read_csv(filepath_or_buffer=path, sep='|')\n",
    "    # There are duplicated samples\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    if option != 'base':\n",
    "        # Drop the useless hour of 'fecha' column\n",
    "        df['fecha'] = df['fecha'].apply(lambda x: x.replace(' 0:00:00', ''))\n",
    "        # Completation of 'precio' column\n",
    "        df['precio'] = df.apply(__price_completer, axis=1)\n",
    "        df['precio'] = df.apply(__price_completer_proximity, axis=1)\n",
    "        # Split of 'fecha' column\n",
    "        df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "        df['dia'] = pd.DatetimeIndex(df['fecha']).day\n",
    "        df['mes'] = pd.DatetimeIndex(df['fecha']).month\n",
    "        df['anyo'] = pd.DatetimeIndex(df['fecha']).year\n",
    "        df.drop('fecha', axis=1, inplace=True)\n",
    "\n",
    "        # One-hot encoding of 'estado'\n",
    "        df = pd.concat([df, pd.get_dummies(pd.get_dummies(\n",
    "            df['estado'], prefix='estado'))], axis=1).drop(['estado'], axis=1)\n",
    "\n",
    "        # One-hot encoding of 'categoria_uno'\n",
    "        df = pd.concat([df, pd.get_dummies(pd.get_dummies(\n",
    "            df['categoria_uno'], prefix='categoria_uno'))], axis=1).drop(['categoria_uno'], axis=1)\n",
    "\n",
    "        # One-hot encoding of 'dia_atipico'\n",
    "        df = pd.concat([df, pd.get_dummies(pd.get_dummies(\n",
    "            df['dia_atipico'], prefix='dia_atipico'))], axis=1).drop(['dia_atipico'], axis=1)\n",
    "\n",
    "        df['antiguedad'].fillna(0, inplace=True)\n",
    "\n",
    "        if option == 'drop':\n",
    "            # 'categoria_dos' drop\n",
    "            df.drop('categoria_dos', axis=1, inplace=True)\n",
    "        else:\n",
    "            # 'categoria_dos' corrupted samples correction\n",
    "            df['categoria_dos'] = df['categoria_dos'].apply(\n",
    "                lambda x: 0 if math.isnan(x) else x)\n",
    "\n",
    "    df.to_csv(index=False, path_or_buf=path.replace(\n",
    "        '.txt', '') + \"_\" + option + \".csv\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Mario\\anaconda3\\envs\\tfg\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3357: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# \"Modelar\" and \"Estimar\" dataframes\n",
    "input_parser(\"data\\Modelar_UH2021.txt\", 'drop')\n",
    "modelar = pd.read_csv(r'data/Modelar_UH2021_drop.csv', sep='|', low_memory=False)\n",
    "# \"Estimar\" dataframe has not samples with \"estado\" = \"Rotura\" and that column is\n",
    "# converted to one-hot vector so it must be dropped\n",
    "modelar = modelar.drop('estado_Rotura', axis=1)\n",
    "input_parser(r\"data\\Estimar_UH2021.txt\", 'drop')\n",
    "estimar = pd.read_csv(r'data/Estimar_UH2021_drop.csv', sep='|', low_memory=False)\n",
    "input_parser(r\"data\\Estimar_UH2021.txt\", 'base')\n",
    "estimar_data = pd.read_csv(r'data/Estimar_UH2021_base.csv', sep='|', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE: 106.45139065900669\nMAE: 2.680797925530872\nFavorable cases: 0.812618870218231\nDatathon metric: 2.006255856266547\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "# Random state seed, to recreate our results\n",
    "rng = 42\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            modelar.loc[:, modelar.columns != 'unidades_vendidas'], modelar['unidades_vendidas'], test_size=0.2, random_state=rng)\n",
    "\n",
    "# Model training\n",
    "model = RandomForestRegressor(n_estimators=150, min_samples_split=3, min_samples_leaf=2, n_jobs=-1, random_state=rng)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model evaluation\n",
    "pred = model.predict(X_test)\n",
    "pred = list(map(lambda x: round(x), pred))\n",
    "cf = __favorable_cases(y_test.values, pred)\n",
    "metric = __datathon_metric(y_test, y_train, pred)\n",
    "\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, pred)))\n",
    "print('MAE: {}'.format(mean_absolute_error(y_test, pred)))\n",
    "print('Favorable cases: {}'.format(cf))\n",
    "print('Datathon metric: {}'.format(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the generation of response file\n",
    "with open('res/Nevermore.txt', 'w') as csv_file:\n",
    "    estimar_prediction = model.predict(estimar)\n",
    "    csv_file.write('FECHA|ID|UNIDADES\\n')\n",
    "    i = 0\n",
    "    for est_pred in estimar_prediction:\n",
    "        csv_file.write(\"{}|{}|{}\\n\".format(estimar_data.iloc[i]['fecha'], int(estimar.iloc[i]['id']), round(est_pred)))\n",
    "        i += 1"
   ]
  }
 ]
}